<html>
<head>
    <title>Jetty WTP Plugin</title>
    <link rel="stylesheet" media="screen, print" href="wiki-style.css"/>
</head>
<body>
<div class="col-md-20" id="mainContent">
                      <ul role="tablist" class="nav nav-tabs noprint hidden-print">
                       <li class="active" id="ca-nstab-main"><a title="View the content page [c]" accesskey="c" href="High Load.html" tabindex="-1">Page</a></li>
                        <li class="new" id="ca-talk"><a tabindex="-1" href="edit" title="Discussion about the content page [t]" accesskey="t">Discussion</a></li>
                        <li id="ca-viewsource"><a accesskey="e" title="This page is protected.&#10;You can view its source [e]" tabindex="-1" href="edit">View source</a></li>
                        <li id="ca-history" class="collapsible"><a accesskey="h" title="Past revisions of this page [h]" tabindex="-1" href="edit">History</a></li>
                      </ul>            <div class="tab-content background-white">
              <div class="tab-pane active" id="tab-pane-main-page-content">

                
                <h1 class="firstHeading page-header" id="firstHeading">
                  <span dir="auto">Jetty/Howto/High Load</span>
                </h1>
                <div id="main-page-content">
                                                      <!-- subtitle -->
                  <div id="contentSub" class="alert alert-small alert-warning"><span class="subpages">&lt; <a href="../../Jetty.html" title="Jetty">Jetty</a>‎ | <a title="Jetty/Howto" href="../Howto.html">Howto</a></span></div>
                  <!-- /subtitle -->
                  
                  
                  <div lang="en" dir="ltr" class="mw-content-ltr" id="mw-content-text"><p><br/>
</p><p><br/>
</p>
<div id="toc" class="toc"><div id="toctitle"><h2>Contents</h2></div>
<ul>
<li class="toclevel-1"><a href="High Load.html#Introduction"><span class="tocnumber">1</span> <span class="toctext">Introduction</span></a></li>
<li class="toclevel-1"><a href="High Load.html#Load_Generation_for_Load_Testing"><span class="tocnumber">2</span> <span class="toctext">Load Generation for Load Testing</span></a></li>
<li class="toclevel-1"><a href="High Load.html#Operating_System_Tuning"><span class="tocnumber">3</span> <span class="toctext">Operating System Tuning</span></a>
<ul>
<li class="toclevel-2"><a href="High Load.html#Linux"><span class="tocnumber">3.1</span> <span class="toctext">Linux</span></a>
<ul>
<li class="toclevel-3"><a href="High Load.html#TCP_Buffer_Sizes"><span class="tocnumber">3.1.1</span> <span class="toctext">TCP Buffer Sizes</span></a></li>
<li class="toclevel-3"><a href="High Load.html#Queue_Sizes"><span class="tocnumber">3.1.2</span> <span class="toctext">Queue Sizes</span></a></li>
<li class="toclevel-3"><a href="High Load.html#Ports"><span class="tocnumber">3.1.3</span> <span class="toctext">Ports</span></a></li>
<li class="toclevel-3"><a href="High Load.html#File_Descriptors"><span class="tocnumber">3.1.4</span> <span class="toctext">File Descriptors</span></a></li>
<li class="toclevel-3"><a href="High Load.html#Congestion_Control"><span class="tocnumber">3.1.5</span> <span class="toctext">Congestion Control</span></a></li>
</ul>
</li>
<li class="toclevel-2"><a href="High Load.html#Mac_OS"><span class="tocnumber">3.2</span> <span class="toctext">Mac OS</span></a></li>
<li class="toclevel-2"><a href="High Load.html#Windows"><span class="tocnumber">3.3</span> <span class="toctext">Windows</span></a></li>
</ul>
</li>
<li class="toclevel-1"><a href="High Load.html#Network_Tuning"><span class="tocnumber">4</span> <span class="toctext">Network Tuning</span></a></li>
<li class="toclevel-1"><a href="High Load.html#JVM_Tuning"><span class="tocnumber">5</span> <span class="toctext">JVM Tuning</span></a></li>
<li class="toclevel-1"><a href="High Load.html#Jetty_Tuning"><span class="tocnumber">6</span> <span class="toctext">Jetty Tuning</span></a>
<ul>
<li class="toclevel-2"><a href="High Load.html#Connectors"><span class="tocnumber">6.1</span> <span class="toctext">Connectors</span></a>
<ul>
<li class="toclevel-3"><a href="High Load.html#Acceptors"><span class="tocnumber">6.1.1</span> <span class="toctext">Acceptors</span></a></li>
<li class="toclevel-3"><a href="High Load.html#Low_Resource_Limits"><span class="tocnumber">6.1.2</span> <span class="toctext">Low Resource Limits</span></a></li>
</ul>
</li>
<li class="toclevel-2"><a href="High Load.html#Thread_Pool"><span class="tocnumber">6.2</span> <span class="toctext">Thread Pool</span></a></li>
</ul>
</li>
</ul>
</div>

<h2><span class="mw-headline" id="Introduction">Introduction</span></h2>
<div class="messagebox" style="background-color: #f9f6b7; border: 1px solid #c4c295; color: black; padding: 5px; margin: 1ex 0; min-height: 35px; padding-left: 45px; font-size: 150%; color: white; background-color: #FF8888; padding: 50px">
<div style="float: left; margin-left: -40px;"><a class="image" href="https://wiki.eclipse.org/File:Warning2.png"><img width="35" height="35" alt="Warning2.png" src="../../images/3/37/Warning2.png"/></a></div>
<div>Jetty 7 and Jetty 8 are now EOL (End of Life)<br/>
<p><br/>
<br/>
<br/>
THIS IS NOT THE DOCUMENTATION YOU ARE LOOKING FOR!!!!!<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
All development and stable releases are being performed with Jetty 9 and Jetty 10.<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
This <b>wiki is now officially out of date</b> and all content has been moved to the <a rel="nofollow" href="http://www.eclipse.org/jetty/documentation" class="external text">Jetty Documentation Hub</a><br/> 
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
</p>
Direct Link to updated documentation: <a class="external free" rel="nofollow" href="http://www.eclipse.org/jetty/documentation/current/high-load.html">http://www.eclipse.org/jetty/documentation/current/high-load.html</a></div>
</div>
<p><br/>
Configuring Jetty for highload, albeit for load testing or for production, requires that the operating system, the JVM, jetty, the application, the network and the load generation all be tuned.
</p>
<h2><span class="mw-headline" id="Load_Generation_for_Load_Testing">Load Generation for Load Testing</span></h2>
<ul><li> The load generation machines must have their OS, JVM etc tuned just as much as the server machines.</li>
<li> The load generation should not be over the local network on the server machine, as this has unrealistic performance and latency as well as different packet sizes and transport characteristics.</li>
<li> The load generator should generate a realistic load:
<ul><li> A common mistake is that load generators often open relatively few connections that are kept totally busy sending as many requests as possible over each connection. This causes the measured throughput to be limited by request latency (see <a href="http://blogs.webtide.com/gregw/entry/lies_damned_lies_and_benchmarks" rel="nofollow" class="external text">Lies Damned Lies and Benchmarks</a> for an analysis of such an issue.</li>
<li> Another common mistake is to use a TCP/IP for a single request and to open many many short lived connections.  This will often result in accept queues filling and limitations due to file descriptor and/or port starvation.</li></ul></li>
<li> A load generator should well model the traffic profile from the normal clients of the server.  For browsers, this if mostly between 2 and 6 connections that are mostly idle and that are used in sporadic bursts with read times in between.  The connections are mostly long held HTTP/1.1 connections.   </li>
<li> Load generators should be written in asynchronous programming style, so that limited threads does not limit the maximum number of users that can be simulated.  If the generator is not asynchronous, then a thread pool of 2000 may only be able to simulate 500 or less users. The Jetty HttpClient is an ideal basis for building a load generator, as it is asynchronous and can be used to simulate many thousands of connections (see the <a rel="nofollow" href="http://cometd.org/documentation/howtos/loadtesting" class="external text">Cometd Load Tester</a> for a good example of a realistic load generator).</li></ul>
<h2><span id="Operating_System_Tuning" class="mw-headline">Operating System Tuning</span></h2>
<p>Both the server machine and any load generating machines need to be tuned to support many TCP/IP connections and high throughput.
</p>
<h3><span class="mw-headline" id="Linux">Linux</span></h3>
<p>Linux does a reasonable job of self configuring TCP/IP, but there are a few limits and defaults that that are best increased.  These can mostly be configured in /etc/security/limits.conf or via sysctl
</p>
<h4><span id="TCP_Buffer_Sizes" class="mw-headline">TCP Buffer Sizes</span></h4>
<p>These should be increased to at least 16MB for 10G paths and tune the autotuning (although buffer bloat now needs to be considered).
</p>
<pre> sysctl -w net.core.rmem_max=16777216
 sysctl -w net.core.wmem_max=16777216
 sysctl -w net.ipv4.tcp_rmem="4096 87380 16777216"
 sysctl -w net.ipv4.tcp_wmem="4096 16384 16777216"
</pre>
<h4><span id="Queue_Sizes" class="mw-headline">Queue Sizes</span></h4>
<p>net.core.somaxconn controls the size of the connection listening queue. The default value of 128 and if you are running a high-volume server and connections are getting refused at a TCP level, then you want to increase this. This is a very tweakable setting in such a case. Too high and you'll get resource problems as it tries to notify a server of a large number of connections and many will remain pending, and too low and you'll get refused connections:
</p>
<pre> sysctl -w net.core.somaxconn=4096
</pre>
<p>The net.core.netdev_max_backlog controls the size of the incoming packet queue for upper-layer (java) processing. The default (2048) may be increased and other related parameters (TODO MORE EXPLANATION) adjusted with:
</p>
<pre> sysctl -w net.core.netdev_max_backlog=16384
 sysctl -w net.ipv4.tcp_max_syn_backlog=8192
 sysctl -w net.ipv4.tcp_syncookies=1
</pre>
<h4><span id="Ports" class="mw-headline">Ports</span></h4>
<p>If many outgoing connections are made (eg on load generators), then the operating system may run low on ports.   Thus it is best to increase the port range used and allow reuse of sockets in TIME_WAIT:
</p>
<pre> sysctl -w net.ipv4.ip_local_port_range="1024 65535"
 sysctl -w net.ipv4.tcp_tw_recycle=1
</pre>
<h4><span id="File_Descriptors" class="mw-headline">File Descriptors</span></h4>
<p>Busy servers and load generators may run out of file descriptors as the system defaults are normally low.  These can be increased for a specific user in /etc/security/limits.conf:
</p>
<pre> theusername		hard nofile	40000
 theusername		soft nofile	40000
</pre>
<p><br/>
</p>
<h4><span id="Congestion_Control" class="mw-headline">Congestion Control</span></h4>
<p>Linux supports pluggable congestion control algorithms. To get a list of congestion control algorithms that are available in your kernel run:
</p>
<pre> sysctl net.ipv4.tcp_available_congestion_control
</pre>
<p>If cubic and/or htcp are not listed then you will need to research the control algorithms for your kernel.  You can try setting the control to cubic with:
</p>
<pre> sysctl -w net.ipv4.tcp_congestion_control=cubic
</pre>
<p><br/>
</p>
<h3><span id="Mac_OS" class="mw-headline">Mac OS</span></h3>
<h3><span id="Windows" class="mw-headline">Windows</span></h3>
<p>Seriously??? 
</p><p><br/>
</p>
<h2><span class="mw-headline" id="Network_Tuning">Network Tuning</span></h2>
<ul><li> Intermediaries such as nginx can use non persistent HTTP/1.0 connection.  Make sure that persistent HTTP/1.1 connections are used.</li></ul>
<h2><span id="JVM_Tuning" class="mw-headline">JVM Tuning</span></h2>
<ul><li> Tune the <a title="Jetty/Howto/Garbage Collection" href="Garbage Collection.html">Garbage Collection</a></li>
<li> Allocate sufficient memory</li>
<li> Use the -server option</li></ul>
<h2><span class="mw-headline" id="Jetty_Tuning">Jetty Tuning</span></h2>
<h3><span id="Connectors" class="mw-headline">Connectors</span></h3>
<h4><span class="mw-headline" id="Acceptors">Acceptors</span></h4>
<p>acceptors &gt;=1 &lt;= # CPUs
</p>
<h4><span class="mw-headline" id="Low_Resource_Limits">Low Resource Limits</span></h4>
<p>Must not be configured for less than the number of expected connections.
</p>
<h3><span class="mw-headline" id="Thread_Pool">Thread Pool</span></h3>
<p>It is very important to limit the task queue of Jetty. By default, the queue is unbounded! As a result, if 
under high load in excess of the processing power of the webapp, jetty will keep a lot of requests on the 
queue. Even after the load has stopped, Jetty will appear to have stopped responding to new requests as it 
still has lots of requests on the queue to handle.
</p><p>For a high reliability system, it should reject the excess requests immediately (fail fast) by using a queue
with a bounded capability. The capability (maximum queue length) should be calculated according to the 
"no-response" time tolerable. For example, if the webapp can handle 100 requests per second, and if you 
can allow it one minute to recover from excessive high load, you can set the queue capability to 60*100=6000. 
If it is set too low, it will reject requests too soon and can't handle normal load spike.
</p><p>Below is a sample configuration:
</p>
<div dir="ltr" class="mw-geshi mw-code mw-content-ltr"><div class="xml source-xml"><pre class="de1"><span class="sc3"><span class="re1">&lt;Configure</span> <span class="re0">id</span>=<span class="st0">"Server"</span> <span class="re0">class</span>=<span class="st0">"org.eclipse.jetty.server.Server"</span><span class="re2">&gt;</span></span>
    <span class="sc3"><span class="re1">&lt;Set</span> <span class="re0">name</span>=<span class="st0">"ThreadPool"</span><span class="re2">&gt;</span></span>
      <span class="sc3"><span class="re1">&lt;New</span> <span class="re0">class</span>=<span class="st0">"org.eclipse.jetty.util.thread.QueuedThreadPool"</span><span class="re2">&gt;</span></span>
        <span class="sc-1">&lt;!-- specify a bounded queue --&gt;</span>
        <span class="sc3"><span class="re1">&lt;Arg<span class="re2">&gt;</span></span></span>
           <span class="sc3"><span class="re1">&lt;New</span> <span class="re0">class</span>=<span class="st0">"java.util.concurrent.ArrayBlockingQueue"</span><span class="re2">&gt;</span></span>
              <span class="sc3"><span class="re1">&lt;Arg</span> <span class="re0">type</span>=<span class="st0">"int"</span><span class="re2">&gt;</span></span>6000<span class="sc3"><span class="re1">&lt;/Arg<span class="re2">&gt;</span></span></span>
           <span class="sc3"><span class="re1">&lt;/New<span class="re2">&gt;</span></span></span>
      <span class="sc3"><span class="re1">&lt;/Arg<span class="re2">&gt;</span></span></span>
        <span class="sc3"><span class="re1">&lt;Set</span> <span class="re0">name</span>=<span class="st0">"minThreads"</span><span class="re2">&gt;</span></span>10<span class="sc3"><span class="re1">&lt;/Set<span class="re2">&gt;</span></span></span>
        <span class="sc3"><span class="re1">&lt;Set</span> <span class="re0">name</span>=<span class="st0">"maxThreads"</span><span class="re2">&gt;</span></span>200<span class="sc3"><span class="re1">&lt;/Set<span class="re2">&gt;</span></span></span>
        <span class="sc3"><span class="re1">&lt;Set</span> <span class="re0">name</span>=<span class="st0">"detailedDump"</span><span class="re2">&gt;</span></span>false<span class="sc3"><span class="re1">&lt;/Set<span class="re2">&gt;</span></span></span>
      <span class="sc3"><span class="re1">&lt;/New<span class="re2">&gt;</span></span></span>
    <span class="sc3"><span class="re1">&lt;/Set<span class="re2">&gt;</span></span></span>
<span class="sc3"><span class="re1">&lt;/Configure<span class="re2">&gt;</span></span></span></pre></div></div>
<p>Configure the number of threads according to the webapp. That is, how many threads it needs
in order to achieve the best performance. Configure with mind to limiting memory usage maximum available.
Typically &gt;50 and &lt;500.
</p>
<!-- 
NewPP limit report
Cached time: 20211116152912
Cache expiry: 86400
Dynamic content: false
CPU time usage: 0.104 seconds
Real time usage: 0.118 seconds
Preprocessor visited node count: 75/1000000
Preprocessor generated node count: 481/1000000
Post‐expand include size: 9409/2097152 bytes
Template argument size: 8062/2097152 bytes
Highest expansion depth: 5/40
Expensive parser function count: 0/100
-->

<!-- 
Transclusion expansion time report (%,ms,calls,template)
100.00%   49.419      1 - -total
100.00%   49.419      1 - Template:Jetty_Howto
 39.10%   19.325      1 - Template:Jetty_Redirect
 26.31%   13.000      1 - Template:Message
 11.49%    5.678      1 - Template:Jetty
-->

<!-- Saved in parser cache with key my_wiki:pcache:idhash:30030-0!*!0!!en!5!* and timestamp 20211116152911 and revision id 348953
 -->
</div>
                                      <!-- catlinks -->
                    <div id="catlinks" class="catlinks"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a title="Special:Categories" href="https://wiki.eclipse.org/Special:Categories">Categories</a>: <ul><li><a title="Category:Jetty" href="https://wiki.eclipse.org/Category:Jetty">Jetty</a></li><li><a href="https://wiki.eclipse.org/Category:Jetty_Howto" title="Category:Jetty Howto">Jetty Howto</a></li></ul></div></div>                     <!-- /catlinks -->
                                  </div>
              </div>
            </div>
          </div>
</body>
</html>
